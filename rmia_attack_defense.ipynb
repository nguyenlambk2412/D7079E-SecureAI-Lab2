{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda2781a",
   "metadata": {},
   "source": [
    "# RMIA Implementation and Experiment\n",
    "\n",
    "This notebook implements the **Ratio Membership Inference Attack (RMIA)** as described in the paper [\"Low-Cost High-Power Membership Inference Attacks\"](https://arxiv.org/html/2312.03262v3#S2).\n",
    "\n",
    "## 1. Concept and Objective\n",
    "**Objective**: To determine whether a specific data point (an image $x$ from CIFAR-10) was part of the training set of a target model (ResNet-18).\n",
    "\n",
    "**Key Idea**: RMIA improves upon simple loss-based attacks by using a **Likelihood Ratio (LR)** test. It compares the probability of the data under the target model against its probability under a \"reference\" model (which represents the general population or \"world\" distribution).\n",
    "\n",
    "### Core Formulas\n",
    "1.  **Likelihood Ratio (LR)**:\n",
    "    $$\n",
    "    LR(x) = \\frac{P(x | \\theta_{target})}{P(x | \\theta_{ref})}\n",
    "    $$\n",
    "    Where:\n",
    "    *   $P(x | \\theta_{target})$ is the confidence of the target model on the true class of $x$.\n",
    "    *   $P(x | \\theta_{ref})$ is the confidence of the reference model (trained on disjoint data) on $x$.\n",
    "\n",
    "2.  **RMIA Score**:\n",
    "    The attack doesn't just look at the raw LR. It checks how \"exceptional\" the LR of $x$ is compared to the LRs of random samples $z$ from the population.\n",
    "    $$\n",
    "    Score_{RMIA}(x) = P_{z \\sim \\mathcal{Z}}(LR(x) > LR(z))\n",
    "    $$\n",
    "    This is empirically calculated as the fraction of population samples $z$ that have a lower Likelihood Ratio than $x$ (i.e., the percentile rank).\n",
    "\n",
    "## 2. Implementation Steps\n",
    "1.  **Data Preparation**: Split CIFAR-10 into four disjoint sets:\n",
    "    *   **Target Members (12.5k)**: Used to train the Target Model.\n",
    "    *   **Reference Members (12.5k)**: Used to train the Reference Model.\n",
    "    *   **Population $Z$ (12.5k)**: Used to compute the normalization statistics for the RMIA score.\n",
    "    *   **Non-Members (10k)**: The official CIFAR-10 test set, used as the \"ground truth\" non-members for evaluation.\n",
    "\n",
    "2.  **Model Training**:\n",
    "    *   Define a ResNet-18 modified for CIFAR-10 (small kernel size, no initial maxpool).\n",
    "    *   Train `Target Model` on Target Members.\n",
    "    *   Train `Reference Model` on Reference Members.\n",
    "    *   *Note: Weights are saved/loaded to avoid re-training.*\n",
    "\n",
    "3.  **Attack Execution**:\n",
    "    *   Calculate $LR(x) = \\frac{P(x | \\theta_{target})}{P(x | \\theta_{ref})}$ : Pass **Target Members** through both models (target and reference models)\n",
    "    *   Calculate $LR(z) = \\frac{P(z | \\theta_{target})}{P(z | \\theta_{ref})}$ : Pass **Population ($Z$)**  through both models (target and reference models)\n",
    "    *   Calculate RMIA Score: For each $x$, count how many $z$'s have a smaller ratio than it (calculate the percentile)\n",
    "    *   Threshold: If Score > $\\beta$ (e.g., 0.5), classify as Member\n",
    "\n",
    "4.  **Evaluation**:\n",
    "    *   Compute the Receiver Operating Characteristic (ROC) curve.\n",
    "    *   Calculate Area Under the Curve (AUC) to measure attack performance (0.5 = random, 1.0 = perfect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a4d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3564b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Model Definition (ResNet-18 adapted for CIFAR-10) ---\n",
    "# Standard ResNet18 is designed for ImageNet (224x224).\n",
    "# For CIFAR-10 (32x32), we need to adjust the initial layers to avoid excessive downsampling.\n",
    "\n",
    "def get_resnet18_cifar10(num_classes=10):\n",
    "    # Load standard ResNet18\n",
    "    model = torchvision.models.resnet18(weights=None)\n",
    "    \n",
    "    # Modify the first convolution layer\n",
    "    # Original: nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    # CIFAR-10: Kernel size 3, stride 1, padding 1 is better to preserve spatial dim\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    \n",
    "    # Remove the first MaxPool layer\n",
    "    # Original: nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    # CIFAR-10: We don't want to downsample this early\n",
    "    model.maxpool = nn.Identity()\n",
    "    \n",
    "    # Modify the fully connected layer for 10 classes\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# --- 2. Helper Functions ---\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "def train_model(model, train_loader, epochs=20, lr=0.1, device=\"cpu\", model_name=\"model\"):\n",
    "    print(f\"Training {model_name} on {device}...\")\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "        scheduler.step()\n",
    "        print(f\"  Epoch [{epoch+1}/{epochs}] Loss: {running_loss/len(train_loader):.4f} Acc: {100.*correct/total:.2f}%\")\n",
    "    \n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def get_probabilities(model, loader, device):\n",
    "    \"\"\"\n",
    "    Returns the probabilities of the TRUE class for each sample.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            softmax_scores = torch.softmax(outputs, dim=1)\n",
    "            \n",
    "            # Select the probability of the true class\n",
    "            true_class_probs = softmax_scores.gather(1, labels.view(-1, 1)).squeeze()\n",
    "            probs.extend(true_class_probs.cpu().numpy())\n",
    "            \n",
    "    return np.array(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9941476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Main Experiment ---\n",
    "\n",
    "data_dir = \"./data\"\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Data Preparation\n",
    "print(\"Preparing Data...\")\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Load Full CIFAR-10\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform_train)\n",
    "# Use testset for evaluation/non-members\n",
    "testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform_test)\n",
    "\n",
    "# Split Trainset\n",
    "# Total 50k. \n",
    "# Target Members: 12.5k\n",
    "# Reference Train: 12.5k (To train the reference model)\n",
    "# Population Z: 12.5k (Used for RMIA normalization)\n",
    "# Unused: 12.5k\n",
    "\n",
    "indices = np.arange(len(trainset))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "idx_target = indices[:12500]\n",
    "idx_ref = indices[12500:25000]\n",
    "idx_pop = indices[25000:37500]\n",
    "\n",
    "# We will use the official test set as \"Non-Members\" for the attack evaluation\n",
    "# to ensure they are strictly out-of-distribution of training.\n",
    "\n",
    "# Create Subsets\n",
    "# Note: For evaluation (computing probs), we should use transform_test (no aug)\n",
    "# So we need a version of trainset with test transforms\n",
    "trainset_eval = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=False, transform=transform_test)\n",
    "\n",
    "ds_target_train = Subset(trainset, idx_target)\n",
    "ds_ref_train = Subset(trainset, idx_ref)\n",
    "\n",
    "ds_target_eval = Subset(trainset_eval, idx_target) # Members (evaluated without aug)\n",
    "ds_pop_eval = Subset(trainset_eval, idx_pop)       # Population Z\n",
    "ds_non_member_eval = testset                       # Non-Members (Test set)\n",
    "\n",
    "# Loaders\n",
    "dl_target_train = DataLoader(ds_target_train, batch_size=batch_size, shuffle=True)\n",
    "dl_ref_train = DataLoader(ds_ref_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dl_target_eval = DataLoader(ds_target_eval, batch_size=batch_size, shuffle=False)\n",
    "dl_non_member_eval = DataLoader(ds_non_member_eval, batch_size=batch_size, shuffle=False)\n",
    "dl_pop_eval = DataLoader(ds_pop_eval, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d986c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Train Target Model ---\n",
    "print(\"\\n--- Training Target Model ---\")\n",
    "target_model = get_resnet18_cifar10()\n",
    "target_model_path = \"target_model.pth\"\n",
    "if os.path.exists(target_model_path):\n",
    "    print(f\"Loading Target Model from {target_model_path}...\")\n",
    "    target_model.load_state_dict(torch.load(target_model_path, map_location=device))\n",
    "    target_model.to(device)\n",
    "    target_model.eval()\n",
    "else:\n",
    "    target_model = train_model(target_model, dl_target_train, epochs=epochs, device=device, model_name=\"Target Model\")\n",
    "    torch.save(target_model.state_dict(), target_model_path)\n",
    "    print(f\"Saved Target Model to {target_model_path}\")\n",
    "\n",
    "# --- Train Reference Model ---\n",
    "print(\"\\n--- Training Reference Model ---\")\n",
    "# In a real attack, you might use multiple reference models. We use 1 for demonstration.\n",
    "ref_model = get_resnet18_cifar10()\n",
    "ref_model_path = \"ref_model.pth\"\n",
    "if os.path.exists(ref_model_path):\n",
    "    print(f\"Loading Reference Model from {ref_model_path}...\")\n",
    "    ref_model.load_state_dict(torch.load(ref_model_path, map_location=device))\n",
    "    ref_model.to(device)\n",
    "    ref_model.eval()\n",
    "else:\n",
    "    ref_model = train_model(ref_model, dl_ref_train, epochs=epochs, device=device, model_name=\"Reference Model\")\n",
    "    torch.save(ref_model.state_dict(), ref_model_path)\n",
    "    print(f\"Saved Reference Model to {ref_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9715ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Perform RMIA Attack ---\n",
    "print(\"\\n--- Computing Probabilities ---\")\n",
    "\n",
    "# P(x | theta_target)\n",
    "prob_target_members = get_probabilities(target_model, dl_target_eval, device)\n",
    "print(\"prob_target_members\", prob_target_members.size)\n",
    "# P(x'| theta_target)\n",
    "prob_target_non_members = get_probabilities(target_model, dl_non_member_eval, device)\n",
    "print(\"prob_target_non_members\", prob_target_non_members.size)\n",
    "# P(z | theta_target)\n",
    "prob_target_z = get_probabilities(target_model, dl_pop_eval, device)\n",
    "print(\"prob_target_z\", prob_target_z.size)\n",
    "# P(x | theta_ref) -> approximates P(x)\n",
    "prob_ref_members = get_probabilities(ref_model, dl_target_eval, device)\n",
    "print(\"prob_ref_members\", prob_ref_members.size)\n",
    "# P(x' | theta_ref)\n",
    "prob_ref_non_members = get_probabilities(ref_model, dl_non_member_eval, device)\n",
    "print(\"prob_ref_non_members\", prob_ref_non_members.size)\n",
    "# P(z | theta_ref)\n",
    "prob_ref_z = get_probabilities(ref_model, dl_pop_eval, device)\n",
    "print(\"prob_ref_z\", prob_ref_z.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebbb8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n--- Calculating RMIA Scores ---\")\n",
    "\n",
    "# Calculate Likelihood Ratios: LR(x) = P(x|Target) / P(x|Ref)\n",
    "# Adding epsilon to avoid division by zero\n",
    "epsilon = 1e-10\n",
    "# LR(x)\n",
    "ratio_members = prob_target_members / (prob_ref_members + epsilon)\n",
    "# LR(z)\n",
    "ratio_z = prob_target_z / (prob_ref_z + epsilon)\n",
    "# LR(non-member)\n",
    "ratio_non_members = prob_target_non_members / (prob_ref_non_members + epsilon)\n",
    "\n",
    "# RMIA Score(x) = Pr( LR(x) > LR(z) )\n",
    "# For each x, we calculate what fraction of z samples have a lower ratio.\n",
    "# This is equivalent to the rank or percentile.\n",
    "\n",
    "def calculate_rmia_score(ratios_eval, ratios_population):\n",
    "    scores = []\n",
    "    # Sort population ratios for binary search (faster) or just broadcasting\n",
    "    # Using broadcasting for clarity\n",
    "    ratios_population = np.array(ratios_population)\n",
    "    for r in ratios_eval:\n",
    "        # Fraction of population ratios that are strictly smaller than r\n",
    "        # (or <=, depending on strictness. The paper uses > gamma)\n",
    "        score = np.mean(r > ratios_population)\n",
    "        scores.append(score)\n",
    "    return np.array(scores)\n",
    "# list of RMIA score: 12500 scores, one for each image in the member set\n",
    "rmia_scores_members = calculate_rmia_score(ratio_members, ratio_z)\n",
    "print(\"rmia_scores_members\", rmia_scores_members.size)\n",
    "# list of RMIA score: 10000 scores, one for each image in the non-member set\n",
    "rmia_scores_non_members = calculate_rmia_score(ratio_non_members, ratio_z)\n",
    "print(\"rmia_scores_non_members\", rmia_scores_non_members.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98964b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Evaluation ---\n",
    "# ground truth: a list of 12500+10000 with 12500 value of 1 for members and 10000 value of 0 for non-member\n",
    "y_true = np.concatenate([np.ones_like(rmia_scores_members), np.zeros_like(rmia_scores_non_members)])\n",
    "print(\"y_true\", y_true.size)\n",
    "# RMIA scores: 12500 scores for members and 10000 score for non-members\n",
    "y_scores = np.concatenate([rmia_scores_members, rmia_scores_non_members])\n",
    "print(\"y_scores\", y_scores.size)\n",
    "# no constant threshold but each of the socre is used as a potential threshold\n",
    "# for each potential threshold, \n",
    "#   classify x is a member if y_score(x) > the threshold and vice versa.\n",
    "#   compare the classification result with the y_true, count no of TP, FP, TN, FN\n",
    "#   calculate the TPR = TP/(TP+FN) and FPR = FP/(FP+TN)\n",
    "# the roc_curve fnc performs all above tasks for the moving thresholds\n",
    "#   fpr and tpr is a list of fpr and tpr with the size of 12500+10000 each\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "print(\"fpr\", fpr.size)\n",
    "print(\"tpr\", tpr.size)\n",
    "print(\"thresholds\", thresholds.size)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(f\"\\nRMIA Attack Results:\")\n",
    "print(f\"AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Plot ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'RMIA ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - RMIA')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('rmia_roc_curve.png')\n",
    "print(\"ROC curve saved to rmia_roc_curve.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
