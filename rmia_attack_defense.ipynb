{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda2781a",
   "metadata": {},
   "source": [
    "# RMIA implementation and experiment with the concept described in the Low-Cost High-Power Membership Inference Attacks paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a4d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "import copy\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3564b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Model Definition (ResNet-18 adapted for CIFAR-10) ---\n",
    "# Standard ResNet18 is designed for ImageNet (224x224).\n",
    "# For CIFAR-10 (32x32), we need to adjust the initial layers to avoid excessive downsampling.\n",
    "\n",
    "def get_resnet18_cifar10(num_classes=10):\n",
    "    # Load standard ResNet18\n",
    "    model = torchvision.models.resnet18(weights=None)\n",
    "    \n",
    "    # Modify the first convolution layer\n",
    "    # Original: nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    # CIFAR-10: Kernel size 3, stride 1, padding 1 is better to preserve spatial dim\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    \n",
    "    # Remove the first MaxPool layer\n",
    "    # Original: nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    # CIFAR-10: We don't want to downsample this early\n",
    "    model.maxpool = nn.Identity()\n",
    "    \n",
    "    # Modify the fully connected layer for 10 classes\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# --- 2. Helper Functions ---\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "def train_model(model, train_loader, epochs=20, lr=0.1, device=\"cpu\", model_name=\"model\"):\n",
    "    print(f\"Training {model_name} on {device}...\")\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "        scheduler.step()\n",
    "        print(f\"  Epoch [{epoch+1}/{epochs}] Loss: {running_loss/len(train_loader):.4f} Acc: {100.*correct/total:.2f}%\")\n",
    "    \n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def get_probabilities(model, loader, device):\n",
    "    \"\"\"\n",
    "    Returns the probabilities of the TRUE class for each sample.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            softmax_scores = torch.softmax(outputs, dim=1)\n",
    "            \n",
    "            # Select the probability of the true class\n",
    "            true_class_probs = softmax_scores.gather(1, labels.view(-1, 1)).squeeze()\n",
    "            probs.extend(true_class_probs.cpu().numpy())\n",
    "            \n",
    "    return np.array(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9941476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Main Experiment ---\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"RMIA Attack on CIFAR-10\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=20, help=\"Number of training epochs\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=128, help=\"Batch size\")\n",
    "    parser.add_argument(\"--data_dir\", type=str, default=\"./data\", help=\"Directory for CIFAR-10 data\")\n",
    "    args = parser.parse_args(args=[])\n",
    "    \n",
    "    device = get_device()\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Data Preparation\n",
    "    print(\"Preparing Data...\")\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    # Load Full CIFAR-10\n",
    "    trainset = torchvision.datasets.CIFAR10(root=args.data_dir, train=True, download=True, transform=transform_train)\n",
    "    # Use testset for evaluation/non-members\n",
    "    testset = torchvision.datasets.CIFAR10(root=args.data_dir, train=False, download=True, transform=transform_test)\n",
    "\n",
    "    # Split Trainset\n",
    "    # Total 50k. \n",
    "    # Target Members: 12.5k\n",
    "    # Reference Train: 12.5k (To train the reference model)\n",
    "    # Population Z: 12.5k (Used for RMIA normalization)\n",
    "    # Unused: 12.5k\n",
    "    \n",
    "    indices = np.arange(len(trainset))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    idx_target = indices[:12500]\n",
    "    idx_ref = indices[12500:25000]\n",
    "    idx_pop = indices[25000:37500]\n",
    "    \n",
    "    # We will use the official test set as \"Non-Members\" for the attack evaluation\n",
    "    # to ensure they are strictly out-of-distribution of training.\n",
    "    \n",
    "    # Create Subsets\n",
    "    # Note: For evaluation (computing probs), we should use transform_test (no aug)\n",
    "    # So we need a version of trainset with test transforms\n",
    "    trainset_eval = torchvision.datasets.CIFAR10(root=args.data_dir, train=True, download=False, transform=transform_test)\n",
    "    \n",
    "    ds_target_train = Subset(trainset, idx_target)\n",
    "    ds_ref_train = Subset(trainset, idx_ref)\n",
    "    \n",
    "    ds_target_eval = Subset(trainset_eval, idx_target) # Members (evaluated without aug)\n",
    "    ds_pop_eval = Subset(trainset_eval, idx_pop)       # Population Z\n",
    "    ds_non_member_eval = testset                       # Non-Members (Test set)\n",
    "\n",
    "    # Loaders\n",
    "    dl_target_train = DataLoader(ds_target_train, batch_size=args.batch_size, shuffle=True)\n",
    "    dl_ref_train = DataLoader(ds_ref_train, batch_size=args.batch_size, shuffle=True)\n",
    "    \n",
    "    dl_target_eval = DataLoader(ds_target_eval, batch_size=args.batch_size, shuffle=False)\n",
    "    dl_non_member_eval = DataLoader(ds_non_member_eval, batch_size=args.batch_size, shuffle=False)\n",
    "    dl_pop_eval = DataLoader(ds_pop_eval, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    # --- Train Target Model ---\n",
    "    print(\"\\n--- Training Target Model ---\")\n",
    "    target_model = get_resnet18_cifar10()\n",
    "    target_model = train_model(target_model, dl_target_train, epochs=args.epochs, device=device, model_name=\"Target Model\")\n",
    "\n",
    "    # --- Train Reference Model ---\n",
    "    print(\"\\n--- Training Reference Model ---\")\n",
    "    # In a real attack, you might use multiple reference models. We use 1 for demonstration.\n",
    "    ref_model = get_resnet18_cifar10()\n",
    "    ref_model = train_model(ref_model, dl_ref_train, epochs=args.epochs, device=device, model_name=\"Reference Model\")\n",
    "\n",
    "    # --- Perform RMIA Attack ---\n",
    "    print(\"\\n--- Computing Probabilities ---\")\n",
    "    \n",
    "    # P(x | theta_target)\n",
    "    prob_target_members = get_probabilities(target_model, dl_target_eval, device)\n",
    "    prob_target_non_members = get_probabilities(target_model, dl_non_member_eval, device)\n",
    "    prob_target_z = get_probabilities(target_model, dl_pop_eval, device)\n",
    "    \n",
    "    # P(x | theta_ref) -> approximates P(x)\n",
    "    prob_ref_members = get_probabilities(ref_model, dl_target_eval, device)\n",
    "    prob_ref_non_members = get_probabilities(ref_model, dl_non_member_eval, device)\n",
    "    prob_ref_z = get_probabilities(ref_model, dl_pop_eval, device)\n",
    "\n",
    "    print(\"\\n--- Calculating RMIA Scores ---\")\n",
    "    \n",
    "    # Calculate Likelihood Ratios: LR(x) = P(x|Target) / P(x|Ref)\n",
    "    # Adding epsilon to avoid division by zero\n",
    "    epsilon = 1e-10\n",
    "    \n",
    "    ratio_members = prob_target_members / (prob_ref_members + epsilon)\n",
    "    ratio_non_members = prob_target_non_members / (prob_ref_non_members + epsilon)\n",
    "    ratio_z = prob_target_z / (prob_ref_z + epsilon)\n",
    "    \n",
    "    # RMIA Score(x) = Pr( LR(x) > LR(z) )\n",
    "    # For each x, we calculate what fraction of z samples have a lower ratio.\n",
    "    # This is equivalent to the rank or percentile.\n",
    "    \n",
    "    def calculate_rmia_score(ratios_eval, ratios_population):\n",
    "        scores = []\n",
    "        # Sort population ratios for binary search (faster) or just broadcasting\n",
    "        # Using broadcasting for clarity\n",
    "        ratios_population = np.array(ratios_population)\n",
    "        for r in ratios_eval:\n",
    "            # Fraction of population ratios that are strictly smaller than r\n",
    "            # (or <=, depending on strictness. The paper uses > gamma)\n",
    "            score = np.mean(r > ratios_population)\n",
    "            scores.append(score)\n",
    "        return np.array(scores)\n",
    "\n",
    "    rmia_scores_members = calculate_rmia_score(ratio_members, ratio_z)\n",
    "    rmia_scores_non_members = calculate_rmia_score(ratio_non_members, ratio_z)\n",
    "    \n",
    "    # --- Evaluation ---\n",
    "    y_true = np.concatenate([np.ones_like(rmia_scores_members), np.zeros_like(rmia_scores_non_members)])\n",
    "    y_scores = np.concatenate([rmia_scores_members, rmia_scores_non_members])\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    print(f\"\\nRMIA Attack Results:\")\n",
    "    print(f\"AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    # Plot ROC\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'RMIA ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic - RMIA')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('rmia_roc_curve.png')\n",
    "    print(\"ROC curve saved to rmia_roc_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09baa04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
